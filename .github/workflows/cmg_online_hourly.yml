name: CMG Online Hourly Update

on:
  schedule:
    # Run every hour at minute 5
    - cron: '5 * * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [main]
    paths:
      - '.github/workflows/cmg_online_hourly.yml'
      - 'scripts/smart_cmg_online_update.py'
      - 'scripts/store_historical.py'

# Prevent concurrent runs to avoid merge conflicts
concurrency:
  group: cmg-online-update
  cancel-in-progress: false  # Wait for previous run to finish

jobs:
  update-cmg-online:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install requests pytz numpy pandas lightgbm xgboost scikit-learn

      # Cache Playwright browsers to avoid re-downloading every run
      - name: Cache Playwright browsers
        uses: actions/cache@v3
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      # ========== STEP 0: FETCH CMG PROGRAMADO ==========
      - name: Fetch CMG Programado forecast (web scraping)
        timeout-minutes: 10
        run: |
          echo "========================================"
          echo "CMG PROGRAMADO - FETCH FORECAST"
          echo "========================================"
          echo "Starting at $(date)"
          echo ""

          # Install Playwright for web scraping
          pip install playwright
          playwright install --with-deps chromium

          # Set environment for headless mode
          export GITHUB_ACTIONS=true

          # Run the CMG Programado pipeline
          python scripts/cmg_programado_pipeline.py

          echo ""
          echo "CMG Programado fetch completed at $(date)"
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 1: FETCH CMG ONLINE ==========
      - name: Fetch CMG Online data from SIP API
        timeout-minutes: 50
        run: |
          echo "========================================"
          echo "CMG ONLINE - FETCH FROM SIP API"
          echo "========================================"
          echo "Starting at $(date)"
          echo ""
          python scripts/smart_cmg_online_update.py
          echo ""
          echo "CMG Online fetch completed at $(date)"
        env:
          PYTHONPATH: ${{ github.workspace }}/api

      # ========== STEP 2: GENERATE ML PREDICTIONS ==========
      - name: Generate ML 24-hour forecast
        if: success()
        timeout-minutes: 5
        run: |
          echo ""
          echo "========================================"
          echo "ML FORECAST - GENERATE PREDICTIONS"
          echo "========================================"
          echo "Starting at $(date)"
          python scripts/ml_hourly_forecast.py
          echo "ML forecast completed at $(date)"
        env:
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 3A: STORE ML PREDICTIONS ==========
      - name: Store ML predictions to dedicated Gist
        if: success()
        timeout-minutes: 5
        run: |
          echo ""
          echo "========================================"
          echo "ML PREDICTIONS - STORE TO GIST"
          echo "========================================"
          echo "Starting at $(date)"
          python scripts/store_ml_predictions.py
          echo "ML predictions stored at $(date)"
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 3B: STORE CMG PROGRAMADO ==========
      - name: Store CMG Programado to dedicated Gist
        if: success()
        timeout-minutes: 5
        run: |
          echo ""
          echo "========================================"
          echo "CMG PROGRAMADO - STORE TO GIST"
          echo "========================================"
          echo "Starting at $(date)"
          python scripts/store_cmg_programado.py
          echo "CMG Programado stored at $(date)"
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 3C: STORE CMG ONLINE ==========
      - name: Store CMG Online to dedicated Gist
        if: success()
        timeout-minutes: 5
        run: |
          echo ""
          echo "========================================"
          echo "CMG ONLINE - STORE TO GIST"
          echo "========================================"
          python scripts/store_historical.py
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 5: VERIFY DATA INTEGRITY ==========
      - name: Verify data integrity
        if: success()
        run: |
          echo ""
          echo "========================================"
          echo "CMG ONLINE - DATA VERIFICATION"
          echo "========================================"
          python -c "
          import json
          from pathlib import Path
          from collections import defaultdict

          # Check CMG Online cache
          cache_file = Path('data/cache/cmg_historical_latest.json')
          if cache_file.exists():
              with open(cache_file) as f:
                  data = json.load(f)
              records = data.get('data', [])
              print(f'‚úÖ Total records: {len(records)}')

              # Check completeness by date
              date_hours = defaultdict(set)
              for r in records:
                  date_hours[r['date']].add(r['hour'])

              print(f'üìä Last 3 days coverage:')
              for date in sorted(date_hours.keys())[-3:]:
                  hours = date_hours[date]
                  if len(hours) == 24:
                      print(f'   ‚úÖ {date}: Complete (24/24 hours)')
                  else:
                      print(f'   ‚ö†Ô∏è  {date}: Incomplete ({len(hours)}/24 hours)')

              # Show metadata
              if 'metadata' in data:
                  meta = data['metadata']
                  print(f'üìÖ Date range: {meta.get(\"oldest_date\")} to {meta.get(\"newest_date\")}')
          else:
              print('‚ùå Cache file not found!')
              exit(1)

          print('========================================')
          "

      # ========== STEP 6: COMMIT CHANGES ==========
      - name: Check for changes
        id: check_changes
        run: |
          git diff --quiet data/ || echo "changed=true" >> $GITHUB_OUTPUT

      - name: Commit and push updates
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Pull latest changes first
          echo "üì• Pulling latest changes..."
          git pull origin main --no-rebase || {
            echo "‚ö†Ô∏è  Pull failed, resetting to origin/main"
            git fetch origin
            git reset --hard origin/main
          }

          # Sync cache files to public/ for Vercel static serving
          echo "üìÇ Syncing cache files to public/data/cache/..."
          mkdir -p public/data/cache
          cp -r data/cache/*.json public/data/cache/
          echo "‚úÖ Cache files synced"

          # Add and commit changes (include downloads folder for CMG Programado CSV)
          git add data/ downloads/ public/data/cache/
          git commit -m "üîÑ CMG Online + ML Predictions + CMG Programado - $(date +'%Y-%m-%d %H:%M')

          - Fetched CMG Programado via web scraping (Playwright)
          - Fetched CMG Online from SIP API (v4/findByDate)
          - Generated ML 24-hour forecast
          - Stored to 3 separate Gists (v3.0):
            ‚Ä¢ ML Predictions: 38b3f9b1cdae5362d3676911ab27f606
            ‚Ä¢ CMG Programado: d68bb21360b1ac549c32a80195f99b09
            ‚Ä¢ CMG Online: 8d7864eb26acf6e780d3c0f7fed69365
          - Updated all cache files
          - Data verified and committed

          Workflow: cmg_online_hourly.yml" || {
            echo "‚ö†Ô∏è  Nothing to commit"
            exit 0
          }

          # Push with retry
          PUSH_SUCCESS=false
          for i in 1 2 3; do
            echo "üì§ Push attempt $i of 3..."
            if git push origin main; then
              echo "‚úÖ Updates pushed successfully!"
              PUSH_SUCCESS=true
              break
            else
              echo "‚ùå Push failed, pulling and retrying..."
              git pull origin main --no-rebase || true
              # In case of conflicts, take the latest data
              git checkout --theirs data/ || true
              git add data/ || true
              git commit --amend --no-edit || true
            fi
          done

          if [ "$PUSH_SUCCESS" = false ]; then
            echo "‚ö†Ô∏è  Could not push after 3 attempts"
            echo "Data is saved locally but not pushed to remote"
            exit 1
          fi

      - name: Trigger Vercel deployment
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          echo "‚úÖ Data updated - Vercel will auto-deploy from main branch"

      - name: Final summary
        if: always()
        run: |
          echo ""
          echo "========================================"
          echo "CMG ONLINE - WORKFLOW SUMMARY"
          echo "========================================"
          echo "Completed at: $(date)"
          echo "Status: ${{ job.status }}"

          if [ -f data/cache/metadata.json ]; then
            echo ""
            echo "Cache metadata:"
            cat data/cache/metadata.json | python -m json.tool | head -15
          fi

          echo ""
          echo "üåê View results:"
          echo "   https://pudidicmgprediction.vercel.app/validation.html"
          echo ""
