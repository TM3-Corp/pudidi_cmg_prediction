name: Unified CMG Data Update

on:
  schedule:
    # Run every hour at minute 5
    - cron: '5 * * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [main]
    paths:
      - '.github/workflows/unified_cmg_update.yml'
      - 'scripts/smart_cmg_online_update.py'
      - 'scripts/sync_from_partner_gist.py'

# Prevent concurrent runs to avoid merge conflicts
concurrency:
  group: cmg-update-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel, wait for previous to finish

jobs:
  update-all-cmg-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          pip install requests pytz numpy
      
      # ========== STEP 1: FETCH CMG ONLINE ==========
      - name: Fetch CMG Online data
        timeout-minutes: 50
        run: |
          cd ${{ github.workspace }}
          echo "========================================"
          echo "STEP 1: FETCHING CMG ONLINE DATA"
          echo "========================================"
          echo "Starting at $(date)"
          python scripts/smart_cmg_online_update.py
          echo "CMG Online fetch completed at $(date)"
        env:
          PYTHONPATH: ${{ github.workspace }}/api
      
      # ========== STEP 2: SYNC CMG PROGRAMADO FOR HISTORICAL REFERENCE ==========
      # NOTE: This only syncs to cmg_programado_history.json for historical comparison
      # It does NOT update the API cache (cmg_programmed_latest.json)
      # The cmg_programado_hourly.yml workflow is the sole owner of CMG Programado API cache
      - name: Sync CMG Programado from Partner Gist (Historical Only)
        if: success()
        timeout-minutes: 5
        run: |
          echo ""
          echo "========================================"
          echo "STEP 2: SYNCING CMG PROGRAMADO (HISTORICAL)"
          echo "========================================"
          echo "üìä Syncing CMG Programado from partner's Gist for historical comparison..."
          echo "‚ö†Ô∏è  Note: This does NOT update the API cache (handled by cmg_programado_hourly.yml)"
          python scripts/sync_from_partner_gist.py
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}

      # REMOVED STEP 3 & 4: CMG Programado cache/gist updates
      # Reason: Caused data overwriting conflicts (72h ‚Üí 28h)
      # These functions are now exclusively handled by cmg_programado_hourly.yml
      # See ARCHITECTURE_ANALYSIS.md for details

      # ========== STEP 3: STORE CMG ONLINE HISTORICAL TO GIST ==========
      - name: Store CMG Online historical data to Gist
        if: success()
        run: |
          echo ""
          echo "========================================"
          echo "STEP 3: STORING CMG ONLINE TO GIST"
          echo "========================================"
          python scripts/store_historical.py
        env:
          GITHUB_TOKEN: ${{ secrets.CMG_GIST_TOKEN }}  # Use PAT with gist permissions
          PYTHONPATH: ${{ github.workspace }}

      # ========== STEP 4: VERIFY DATA INTEGRITY ==========
      - name: Verify data integrity
        if: success()
        run: |
          echo ""
          echo "========================================"
          echo "DATA INTEGRITY CHECK"
          echo "========================================"
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime
          import pytz
          
          # Check CMG Online cache
          cache_file = Path('data/cache/cmg_historical_latest.json')
          if cache_file.exists():
              with open(cache_file) as f:
                  data = json.load(f)
              records = data.get('data', [])
              print(f'‚úÖ CMG Online: {len(records)} records')
              
              # Check completeness by date
              from collections import defaultdict
              date_hours = defaultdict(set)
              for r in records:
                  date_hours[r['date']].add(r['hour'])
              
              for date in sorted(date_hours.keys())[-3:]:
                  hours = date_hours[date]
                  if len(hours) == 24:
                      print(f'   ‚úÖ {date}: Complete (24/24 hours)')
                  else:
                      print(f'   ‚ö†Ô∏è {date}: {len(hours)}/24 hours')
          
          # Check CMG Programado
          prog_file = Path('data/cmg_programado_history.json')
          if prog_file.exists():
              with open(prog_file) as f:
                  data = json.load(f)
              hist = data.get('historical_data', {})
              total_hours = sum(len(h) for h in hist.values())
              print(f'‚úÖ CMG Programado: {len(hist)} days, {total_hours} hours')
          
          print('========================================')"

      # ========== STEP 5: COMMIT CHANGES ==========
      - name: Check for changes
        id: check_changes
        run: |
          git diff --quiet data/ || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push updates
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Stash any local changes first
          git stash || true
          
          # Pull latest changes
          echo "üì• Pulling latest changes..."
          git pull origin main --no-rebase || {
            echo "‚ö†Ô∏è Pull failed, resetting to origin/main"
            git fetch origin
            git reset --hard origin/main
          }
          
          # Apply our changes on top
          git stash pop || true
          
          # Add and commit changes
          git add data/
          git commit -m "üîÑ CMG Online update - $(date +'%Y-%m-%d %H:%M')

          - CMG Online data fetched from SIP API
          - CMG Online Gist updated
          - CMG Programado historical synced (reference only)
          - Data integrity verified

          Note: CMG Programado API cache managed by cmg_programado_hourly.yml" || {
            echo "‚ö†Ô∏è Nothing to commit"
            exit 0
          }
          
          # Push with retry
          PUSH_SUCCESS=false
          for i in 1 2 3; do
            echo "üì§ Push attempt $i of 3..."
            if git push origin main; then
              echo "‚úÖ Updates pushed successfully!"
              PUSH_SUCCESS=true
              break
            else
              echo "‚ùå Push failed, pulling and retrying..."
              git pull origin main --no-rebase || true
              # In case of conflicts, just take the latest data
              git checkout --theirs data/ || true
              git add data/ || true
              git commit --amend --no-edit || true
            fi
          done
          
          if [ "$PUSH_SUCCESS" = false ]; then
            echo "‚ö†Ô∏è Could not push after 3 attempts, but data is saved locally"
            # Don't fail the workflow, data is still good
            exit 0
          fi
      
      - name: Trigger Vercel deployment
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          echo "‚úÖ Data updated - Vercel will auto-deploy"
      
      - name: Final summary
        if: always()
        run: |
          echo ""
          echo "========================================"
          echo "WORKFLOW SUMMARY"
          echo "========================================"
          echo "Completed at: $(date)"
          echo "Status: ${{ job.status }}"
          if [ -f data/cache/metadata.json ]; then
            echo "Cache metadata:"
            cat data/cache/metadata.json | python -m json.tool | head -20
          fi