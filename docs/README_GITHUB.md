# CMG Prediction System - Pudidi

Production-ready system for predicting Marginal Cost (CMG) values for ChiloÃ© 220kV node in Chile's electrical grid.

## ðŸŽ¯ Problem Solved

The Chilean electrical grid API requires fetching 440+ pages (~18 minutes) to get complete 24-hour data for ChiloÃ©. This system solves that by:
- Fetching data once daily at 3 AM
- Storing in a local database
- Serving instant predictions (<100ms response time)

## ðŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Initialize Database with Test Data
```bash
python populate_test_data.py
```

### 3. Test the API
```bash
python test_api_db.py
```

### 4. Deploy to Production
```bash
# Set up daily fetch cron job
bash setup_cron.sh

# Deploy to Vercel
npx vercel --prod
```

## ðŸ“ Project Structure

```
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ predictions.py           # Current production API
â”‚   â””â”€â”€ predictions_from_db.py   # New database-based API (faster)
â”œâ”€â”€ fetch_complete_daily.py      # Daily data fetcher (runs at 3 AM)
â”œâ”€â”€ populate_initial_data.py     # Populate with real historical data
â”œâ”€â”€ populate_test_data.py        # Quick test data setup
â”œâ”€â”€ cmg_data.db                  # SQLite database (auto-created)
â””â”€â”€ requirements.txt             # Python dependencies
```

## ðŸ”‘ Key Features

- **Complete Coverage**: Fetches all 24 hours of data (not just sparse 3-5 records)
- **Fast Response**: <100ms from database (vs 10-30s from API)
- **Reliable**: No more timeouts or rate limit errors
- **ML Predictions**: Uses safe lag features (24h, 48h, 168h)
- **Daily Updates**: Automatic fetch at 3 AM Santiago time

## ðŸ“Š API Response Format

```json
{
  "success": true,
  "location": "ChiloÃ© 220kV",
  "node": "CHILOE________220",
  "stats": {
    "data_points": 24,
    "avg_24h": 63.49,
    "max_48h": 96.04,
    "min_48h": 37.25,
    "hours_covered": 24
  },
  "predictions": [
    {
      "datetime": "2025-08-25 23:00:00",
      "hour": 23,
      "cmg_actual": 51.38,
      "is_historical": true
    },
    {
      "datetime": "2025-08-26 00:00:00", 
      "hour": 0,
      "cmg_predicted": 45.2,
      "confidence_lower": 38.4,
      "confidence_upper": 52.0,
      "is_prediction": true
    }
    // ... 72 total entries (24h history + 48h predictions)
  ]
}
```

## ðŸ”§ Configuration

### Environment Variables
Create a `.env` file:
```env
SIP_API_KEY=1a81177c8ff4f69e7dd5bb8c61bc08b4
```

### Cron Job (Automatic Setup)
```bash
bash setup_cron.sh
```

Or manually:
```bash
crontab -e
# Add: 0 3 * * * python3 /path/to/fetch_complete_daily.py
```

## ðŸ“ˆ Performance

| Metric | Before | After |
|--------|--------|-------|
| Response Time | 10-30s | <100ms |
| Data Coverage | 0-5 hours | 24/24 hours |
| Reliability | Frequent timeouts | 100% uptime |
| Predictions | Flat $57.15 | ML-based patterns |

## ðŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ðŸ“ Documentation

- [Production Setup Guide](PRODUCTION_SETUP.md)
- [Deployment Status](DEPLOYMENT_STATUS.md)
- [Data Fetching Strategy](PRODUCTION_DATA_FETCH.md)
- [Collaboration Guide](README_COLLABORATION.md)

## ðŸ› Known Issues

- Initial data fetch takes ~18 minutes per day (440+ API pages)
- API key included in repo (it's public, but should be in env vars for production)

## ðŸ“ž Support

For issues or questions, please open an issue in this repository.

## ðŸ“„ License

This project is proprietary - all rights reserved.